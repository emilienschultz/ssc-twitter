{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33536b66-f1c4-4342-adc3-7b4d52c161b8",
   "metadata": {},
   "source": [
    "# Etape 1 : mise en forme des données\n",
    "\n",
    "*Durée prévisionnelle : 1h*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380aa957-b63e-4eaf-839d-bed96cfae2a8",
   "metadata": {},
   "source": [
    "Cette première étape nécessite de se confronter aux données réelles qui ne sont pas nécessairement structurées comme souhaitée, et mettre en place les étapes de consolidation (*data management*).\n",
    "\n",
    "Objectif du notebook :\n",
    "\n",
    "1. produire un dataset manipulable\n",
    "2. débuter des statistiques de caractérisation\n",
    "\n",
    "Choix : ne pas recourir à une base de données car nous sommes dans l'exploratoire. Cela pourrait être une des débouchées de la réflexion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47f267-998f-4d32-8288-dda98a7417e4",
   "metadata": {},
   "source": [
    "## 1. Format des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca382620-1e4a-4766-b21a-364c4571131b",
   "metadata": {},
   "source": [
    "Les données ont été collectées au fil de l'eau par une interface spécialisée (Gazouilloire, de Sciences Po). Si le tweet fait partie d'un thread, tout le thread est récupéré. La collecte a été lancée à partir du 1ier mars 2020, et dans ce cas ce jeu de données s'arrête en octobre 2020. Il y a un fichier par jour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c277d6-89e1-4ad5-b27f-a6e3d2f69b8d",
   "metadata": {},
   "source": [
    "Vous pouvez télécharger les données ici : https://www.dropbox.com/scl/fo/21bfj3fq3nac3ix1rccvn/h?rlkey=dk5pxipkfwdx4d709ro294r2i&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de6fea-f21e-465f-af70-55fd450b7c29",
   "metadata": {},
   "source": [
    "### Comprendre la structuration des données\n",
    "\n",
    "- Charger un fichier avec pandas ?\n",
    "- Quelles sont les données ? Qu'est-ce qui caractérise un tweet ?\n",
    "- Quel est le format ? Quels sont les différents champs ? Que signifient ces champs ?\n",
    "- Est-ce que tout nous intéresse ? Faire une sélection des champs d'intérêt pour étudier 1/ l'évolution temporelle des tweets ; 2/ les comptes actifs ; 3/ les relations entre les comptes (retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb595b9e-8e2f-4103-9fb3-dff84fdcc488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e3c2e-fa15-47dd-9dd5-af497636160f",
   "metadata": {},
   "source": [
    "On peut spécifier le type de données lors de l'ouverture avec Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93466d58-c7e1-4094-a8df-4481e023770f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65587, 57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep = \"../../../Données/Tweets_HCQ/\" # où les données sont téléchargées\n",
    "\n",
    "df = pd.read_csv(rep + \"2020-09-10.csv.gz\",\n",
    "                 dtype = {\"id\":str,\"quoted_id\":str,\"retweeted_user_id\":str}\n",
    "                )\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1e87b0-6dbf-4486-995c-7f96014d316c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'time', 'created_at', 'from_user_name', 'text', 'filter_level',\n",
       "       'possibly_sensitive', 'withheld_copyright', 'withheld_scope',\n",
       "       'withheld_countries', 'truncated', 'retweet_count', 'favorite_count',\n",
       "       'reply_count', 'lang', 'to_user_name', 'to_user_id',\n",
       "       'in_reply_to_status_id', 'source', 'source_name', 'source_url',\n",
       "       'location', 'lat', 'lng', 'from_user_id', 'from_user_realname',\n",
       "       'from_user_verified', 'from_user_description', 'from_user_url',\n",
       "       'from_user_profile_image_url', 'from_user_utcoffset',\n",
       "       'from_user_timezone', 'from_user_lang', 'from_user_tweetcount',\n",
       "       'from_user_followercount', 'from_user_friendcount',\n",
       "       'from_user_favourites_count', 'from_user_listed',\n",
       "       'from_user_withheld_scope', 'from_user_withheld_countries',\n",
       "       'from_user_created_at', 'collected_via_search', 'collected_via_stream',\n",
       "       'collected_via_thread_only', 'collected_at_timestamp', 'retweeted_id',\n",
       "       'retweeted_user_name', 'retweeted_user_id', 'quoted_id',\n",
       "       'quoted_user_name', 'quoted_user_id', 'links', 'medias_urls',\n",
       "       'medias_files', 'mentioned_user_names', 'mentioned_user_ids',\n",
       "       'hashtags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbe3d6-0d48-410c-81c1-1ad5a9bbf5af",
   "metadata": {},
   "source": [
    "On veut garder certains champs\n",
    "\n",
    "    id\n",
    "    created_at\n",
    "    lang\n",
    "    text\n",
    "    from_user_name\n",
    "    from_user_tweetcount\n",
    "    from_user_followercount\n",
    "    from_user_friendcount\n",
    "    retweeted_id\n",
    "    retweeted_user_name\n",
    "    quoted_user_id\n",
    "    mentioned_user_names\n",
    "    hashtags\n",
    "    links\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a08ba-e85d-4f41-ba63-3c8346c3a4b2",
   "metadata": {},
   "source": [
    "> Penser à travailler sur un sous-échantillon du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eccfe6-4800-4e40-808d-1d7ab1eac22c",
   "metadata": {},
   "source": [
    "## 2. Mise en forme de la base de données\n",
    "\n",
    "La première étape est de consolider les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5419330-343a-4343-a7c3-30a0283e17be",
   "metadata": {},
   "source": [
    "### Ecrire une fonction qui filtre les tweets d'un jour et la tester sur un fichier CSV\n",
    "\n",
    "- garder uniquement les tweets qui mentionnent le mot clé d'intérêt chloro*\n",
    "- qui sont en français\n",
    "- en enlevant les colonnes qui ne nous intéressent pas pour avoir un dataset plus manipulable\n",
    "- mettre les id en chaînes de caractères pour éviter certains problèmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3cdaca-bdeb-4a90-a9ad-dcebdf5ce03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25234/1239793293.py:7: DtypeWarning: Columns (8,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tableau = pd.read_csv(nom_fichier,dtype={\"id\":str,\"quoted_user_id\":str,\n"
     ]
    }
   ],
   "source": [
    "nom_fichier = rep + \"2020-04-08.csv.gz\"\n",
    "\n",
    "def filtrer_tableau_tweets(nom_fichier):\n",
    "    \"\"\"\n",
    "    Ouvrir et renvoyer le tableau filtré\n",
    "    \"\"\"\n",
    "    tableau = pd.read_csv(nom_fichier,dtype={\"id\":str,\"quoted_user_id\":str,\n",
    "                                             \"retweeted_id\":str,\n",
    "                                             \"retweeted_user_id\":str})\n",
    "    cols = [\"id\",\"created_at\",\"lang\",\"text\",\n",
    "            \"from_user_name\",\"from_user_tweetcount\",\"from_user_followercount\",\"from_user_friendcount\",\n",
    "            \"retweeted_id\",\"quoted_user_id\",\"mentioned_user_names\",\"hashtags\",\"links\",\n",
    "            'retweeted_user_name', 'retweeted_user_id']\n",
    "    f_lang = tableau[\"lang\"] == \"fr\"\n",
    "    f_mc = tableau[\"text\"].str.lower().str.contains(\"chloro|chl0r0|chlor0|chl0ro\")\n",
    "    return tableau[f_lang & f_mc][cols]\n",
    "\n",
    "df = filtrer_tableau_tweets(nom_fichier)\n",
    "\n",
    "rep_cible = \"../../../Données/fichiers_parquet/\"\n",
    "\n",
    "df.to_parquet(\"2020-04-08.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e98fb-00bc-4258-b513-15315e8ecdfc",
   "metadata": {},
   "source": [
    "### Traiter l'ensemble des données pour construire une structure de données parquet qui ne contient que les données filtrées\n",
    "\n",
    "- Convertir un fichier csv en parquet avec pandas\n",
    "- Tester la vitesse d'ouverture\n",
    "- Convertir l'ensemble des fichiers en chargeant les CSV, en les filtrant, en conservant les éléments filtrés dans une liste, puis en écrivant l'ensemble dans un fichier parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf1e29-67d0-45e8-b00f-b3e717182125",
   "metadata": {},
   "source": [
    "Test le la lecture des fichiers parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5624b1e-095a-4193-b49c-15aaa216bde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_parquet(\"test.parquet\")\n",
    "df.to_csv(\"test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a1adf49-96bb-4597-9617-26a6ea25b1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.3 ms, sys: 24 ms, total: 91.3 ms\n",
      "Wall time: 64 ms\n",
      "CPU times: user 246 ms, sys: 12.1 ms, total: 258 ms\n",
      "Wall time: 257 ms\n"
     ]
    }
   ],
   "source": [
    "%time df = pd.read_parquet(\"test.parquet\")\n",
    "%time df = pd.read_csv(\"test.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16674828-32a7-48af-815f-fa3edd2a689b",
   "metadata": {},
   "source": [
    "> Pour faciliter la gestion mémoire : lire chaque csv en chunk et sauvegarder chaque fichier dans un format parquet dans un dossier commun. Mais attention, il y a un enjeu à bien définir un format commun sinon il peut y avoir des soucis.\n",
    "\n",
    "Sur Parquet & CSV https://www.icem7.fr/cartographie/parquet-devrait-remplacer-le-format-csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0eb867-da08-4dfc-9667-7383bfcc36ca",
   "metadata": {},
   "source": [
    "> Il est possible de créer un seul fichier parquet, mais pour cela il faut gérer correctement le schéma de la base avec `pyarrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999f8b6-3611-4d0c-a47a-f36553c0b815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Dossiers concernés\n",
    "rep = \"../../../Données/Tweets_HCQ/\"\n",
    "\n",
    "# ne garder que les noms de fichiers qui ont \"2020\" dedans (correspondant à notre période)\n",
    "fichiers = [i for i in os.listdir(rep) if \"2020\" in i]\n",
    "\n",
    "# liste des tweets filtrés\n",
    "corpus = []\n",
    "\n",
    "# Boucle sur tous les fichiers\n",
    "for f in fichiers:\n",
    "    # print(repertoire + f)\n",
    "    # lire et filtrer un fichier avec la fonction\n",
    "    df = filtrer_tableau_tweets(rep + f)\n",
    "    \n",
    "    # ajouter au corpus\n",
    "    corpus.append(df)\n",
    "\n",
    "# concaténer l'ensemble des tweets dans un dataframe\n",
    "df = pd.concat(corpus)\n",
    "\n",
    "# Écrire dans un fichier parquet unique\n",
    "df.to_parquet(\"dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc56f9-83ef-4ef3-b51a-45571e678a0e",
   "metadata": {},
   "source": [
    "### Charger les données filtrées, supprimer les doublons et compléter la base en calculant le nombre de reweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e4a33-27ae-44d9-a1a3-8eb6b1853888",
   "metadata": {},
   "source": [
    "Charger les données (soit le dossier ; soit le fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb79b97e-bcaa-478c-9345-7fb58357f7df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3788348, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"dataset.parquet\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1a70c-17b1-4014-a1d0-66ef08017b7f",
   "metadata": {},
   "source": [
    "Dédoublonnons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b4bd04-2d0a-4b42-a906-248edd251be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc97203-bb5b-491b-ae30-b4029e270c34",
   "metadata": {},
   "source": [
    "Calculer les retweets et les ajouter au dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f50cb99-2268-4cc4-9f9b-71928d4ed8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retweets = df[\"retweeted_id\"].value_counts()\n",
    "df = df.join(retweets,on=\"id\")\n",
    "df = df.rename(columns={\"count\":\"retweet\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d0774-28e2-45bc-ada6-9e6ba64f13a9",
   "metadata": {},
   "source": [
    "Sauvegarder le nouveau dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ef117a-e4fc-4fad-acb3-f6f6c9c54b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_parquet(\"dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f90f57-84b5-40e4-98f5-c9ffac80d7da",
   "metadata": {},
   "source": [
    "## 3. Faire des statistiques sur les tweets (comptage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1555dcc-ab65-418f-83f5-7a5628e8e249",
   "metadata": {},
   "source": [
    "### Débuter l'exploration des données avec des statistiques descriptives du corpus\n",
    "\n",
    "- nombre de tweets originaux\n",
    "- nombre de retweet\n",
    "- comptes ayant le plus de tweets originaux\n",
    "    - regarder les tweets associés\n",
    "- Identifier les tweets les plus retweetés du corpus\n",
    "- comptes ayant le plus de retweets total (plus grande viralité)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb8b14-d141-4364-a82c-093ff93274c2",
   "metadata": {},
   "source": [
    "Proportion tweets originaux / total des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12c8bc23-e15c-4ea2-a5ae-f599aeab04f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17182932388592123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df[\"retweeted_id\"]).sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34958030-52a5-4c33-814f-054718a85492",
   "metadata": {},
   "source": [
    "Calculer le nombre de tweets originaux par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6b434f4-f24a-4190-8165-dcd454fabd8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from_user_name\n",
       "00000CHANEL          0\n",
       "audescande           0\n",
       "auderaiplie          0\n",
       "audemazoue           0\n",
       "audemannoury         0\n",
       "                  ... \n",
       "lan1794           1333\n",
       "InfoVeryfiable    1337\n",
       "GBOU66            1824\n",
       "zenutopia1        2022\n",
       "a_1_0_2           2038\n",
       "Name: original, Length: 442388, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"original\"] = pd.isnull(df[\"retweeted_id\"])\n",
    "df.groupby(\"from_user_name\")[\"original\"].sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f258fd-f455-406c-b60f-5f870133f28c",
   "metadata": {},
   "source": [
    "Nombre total de retweets obtenus par les comptes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cf00d3d-6904-4faa-b01e-11fb434eaf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from_user_name\n",
       "00000CHANEL             0.0\n",
       "chicaa135               0.0\n",
       "chibron_bac2bac         0.0\n",
       "chibre59                0.0\n",
       "chibdan4christ          0.0\n",
       "                     ...   \n",
       "CorinneReverbel     33655.0\n",
       "Conflits_FR         41617.0\n",
       "medicalfollower     77274.0\n",
       "biobiobiobior      136669.0\n",
       "raoult_didier      189286.0\n",
       "Name: retweet, Length: 442388, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"from_user_name\")[\"retweet\"].sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba306167-b4c8-4dcb-bbbd-6cce1a4d7133",
   "metadata": {},
   "source": [
    "### (pas traité en cours) Aller vers une visualisation\n",
    "\n",
    "- Visualiser la distribution des retweets par tweet\n",
    "- Proposer une visualisation de la diversité de l'activité des comptes (volume de tweets, viralité, taille des comptes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67e095-9212-4da9-944b-f4a1542ced11",
   "metadata": {},
   "source": [
    "> Pour la visualisation : \n",
    ">- en x : nombre d'abonnés\n",
    ">- en y : nombre de tweets fait\n",
    ">- en taille nombre de retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407e159-552a-443b-8f2a-ffe0192b2205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cbf92c2-5a5d-4bdc-bd0c-3ed10606a82f",
   "metadata": {},
   "source": [
    "### (pas traité en cours) Bonus : Analyser les biographies des comptes\n",
    "\n",
    "- Sortir un fichier comptes/bio pour les comptes qui ont fait au moins 10 tweets originaux\n",
    "    - Quelle bio sélectionner ?\n",
    "\n",
    "Construire un jeu de données par comptes qui ont au moins 2 activités :\n",
    "\n",
    "- nom\n",
    "- bio\n",
    "- date premier tweet/retweet\n",
    "- date dernier tweet/retweet\n",
    "- nombre de tweet\n",
    "- nombre de retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91581e0-d79f-48a4-a2a8-016cb746016f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
